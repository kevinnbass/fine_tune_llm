{
  "class_name": "LLMEvaluator",
  "functionality_map": {
    "file_info": {
      "path": "C:\\Users\\Kevin\\fine_tune_llm\\backups\\god_classes\\evaluate_backup_20250814_121303.py",
      "size": 44687,
      "lines": 1064,
      "non_empty_lines": 885,
      "comment_lines": 109
    },
    "imports": {
      "stdlib": [
        "json",
        "logging"
      ],
      "third_party": [
        "numpy",
        "pandas",
        "torch",
        "matplotlib.pyplot",
        "seaborn"
      ],
      "local": [
        "yaml",
        "evaluate",
        "argparse"
      ],
      "from_imports": {
        "pathlib": {
          "category": "stdlib",
          "items": [
            "Path"
          ]
        },
        "typing": {
          "category": "stdlib",
          "items": [
            "Dict",
            "List",
            "Tuple",
            "Optional"
          ]
        },
        "sklearn.metrics": {
          "category": "third_party",
          "items": [
            "accuracy_score",
            "f1_score",
            "precision_score",
            "recall_score",
            "confusion_matrix"
          ]
        },
        "transformers": {
          "category": "third_party",
          "items": [
            "AutoModelForCausalLM",
            "AutoTokenizer"
          ]
        },
        "peft": {
          "category": "local",
          "items": [
            "PeftModel"
          ]
        },
        "datasets": {
          "category": "third_party",
          "items": [
            "Dataset"
          ]
        },
        "tqdm": {
          "category": "local",
          "items": [
            "tqdm"
          ]
        },
        "datetime": {
          "category": "stdlib",
          "items": [
            "datetime"
          ]
        },
        "metrics": {
          "category": "local",
          "items": [
            "compute_ece",
            "compute_mce",
            "compute_brier_score",
            "compute_abstention_metrics",
            "compute_risk_aware_metrics",
            "compute_confidence_metrics",
            "MetricsAggregator",
            "compute_reliability_diagram_data"
          ]
        },
        "conformal": {
          "category": "local",
          "items": [
            "ConformalPredictor",
            "RiskControlledPredictor"
          ]
        },
        "collections": {
          "category": "stdlib",
          "items": [
            "Counter"
          ]
        }
      },
      "import_aliases": {
        "np": "numpy",
        "pd": "pandas",
        "plt": "matplotlib.pyplot",
        "sns": "seaborn"
      }
    },
    "classes": {
      "LLMEvaluator": {
        "name": "LLMEvaluator",
        "line_start": 43,
        "line_end": 745,
        "bases": [],
        "decorators": [],
        "methods": {
          "__init__": {
            "name": "__init__",
            "line_start": 46,
            "line_end": 112,
            "line_count": 67,
            "parameters": [
              "self",
              "model",
              "tokenizer",
              "model_path",
              "config_path"
            ],
            "decorators": [],
            "docstring": "Initialize evaluator.\n\nArgs:\n    model: Model instance for evaluation\n    tokenizer: Tokenizer instance  \n    model_path: Optional path to fine-tuned model\n    config_path: Path to configuration file",
            "has_args": false,
            "has_kwargs": false,
            "is_async": false,
            "calls_made": [
              "Path",
              "self.load_config",
              "MetricsAggregator",
              "self.config.get",
              "get",
              "get",
              "logger.info",
              "evaluate.load",
              "evaluate.load",
              "evaluate.load",
              "evaluate.load",
              "Path",
              "get",
              "get",
              "ConformalPredictor",
              "logger.info",
              "RiskControlledPredictor",
              "logger.info",
              "advanced_config.get",
              "advanced_config.get",
              "Path"
            ],
            "complexity": 6,
            "return_count": 0,
            "returns_none": false
          },
          "load_config": {
            "name": "load_config",
            "line_start": 114,
            "line_end": 117,
            "line_count": 4,
            "parameters": [
              "self"
            ],
            "decorators": [],
            "docstring": "Load configuration.",
            "has_args": false,
            "has_kwargs": false,
            "is_async": false,
            "calls_made": [
              "open",
              "yaml.safe_load"
            ],
            "complexity": 0,
            "return_count": 0,
            "returns_none": false
          },
          "load_model": {
            "name": "load_model",
            "line_start": 119,
            "line_end": 135,
            "line_count": 17,
            "parameters": [
              "self"
            ],
            "decorators": [],
            "docstring": "Load the fine-tuned model.",
            "has_args": false,
            "has_kwargs": false,
            "is_async": false,
            "calls_made": [
              "logger.info",
              "AutoTokenizer.from_pretrained",
              "AutoModelForCausalLM.from_pretrained",
              "logger.info"
            ],
            "complexity": 0,
            "return_count": 0,
            "returns_none": false
          },
          "evaluate_single": {
            "name": "evaluate_single",
            "line_start": 137,
            "line_end": 139,
            "line_count": 3,
            "parameters": [
              "self",
              "text",
              "parse_json"
            ],
            "decorators": [],
            "docstring": "Evaluate a single text input.",
            "has_args": false,
            "has_kwargs": false,
            "is_async": false,
            "calls_made": [
              "self.predict_single"
            ],
            "complexity": 0,
            "return_count": 1,
            "returns_none": false
          },
          "predict_single": {
            "name": "predict_single",
            "line_start": 141,
            "line_end": 214,
            "line_count": 74,
            "parameters": [
              "self",
              "text",
              "metadata"
            ],
            "decorators": [],
            "docstring": "Generate prediction for a single text.\n\nArgs:\n    text: Input text\n    metadata: Additional metadata\n\nReturns:\n    Prediction dictionary",
            "has_args": false,
            "has_kwargs": false,
            "is_async": false,
            "calls_made": [
              "strip",
              "self.tokenizer",
              "self.tokenizer.decode",
              "len",
              "strip",
              "torch.no_grad",
              "self.model.generate",
              "self.tokenizer.decode",
              "generated_text.find",
              "generated_text.rfind",
              "json.loads",
              "result.get",
              "result.get",
              "result.get",
              "result.get"
            ],
            "complexity": 2,
            "return_count": 3,
            "returns_none": false
          },
          "evaluate_dataset": {
            "name": "evaluate_dataset",
            "line_start": 216,
            "line_end": 303,
            "line_count": 88,
            "parameters": [
              "self",
              "dataset",
              "batch_size",
              "output_path"
            ],
            "decorators": [],
            "docstring": "Evaluate model on a dataset.\n\nArgs:\n    dataset: Evaluation dataset (list of dicts or Dataset)\n    batch_size: Batch size for processing\n    output_path: Optional path to save detailed results\n\nReturns:\n    List of evaluation results",
            "has_args": false,
            "has_kwargs": false,
            "is_async": false,
            "calls_made": [
              "logger.info",
              "enumerate",
              "hasattr",
              "hasattr",
              "tqdm",
              "Path",
              "output_dir.mkdir",
              "logger.info",
              "self.predict_single",
              "example.get",
              "pred.get",
              "detailed_results.append",
              "open",
              "json.dump",
              "range",
              "len",
              "example.get",
              "example.get",
              "example.get",
              "example.get",
              "detailed_results.append",
              "logger.warning",
              "len",
              "example.get",
              "example.get",
              "json.loads",
              "example.get",
              "example.get",
              "str",
              "example.get",
              "example.get"
            ],
            "complexity": 7,
            "return_count": 2,
            "returns_none": false
          },
          "compute_metrics": {
            "name": "compute_metrics",
            "line_start": 305,
            "line_end": 468,
            "line_count": 164,
            "parameters": [
              "self",
              "predictions",
              "ground_truth",
              "detailed_results"
            ],
            "decorators": [],
            "docstring": "Compute comprehensive evaluation metrics including advanced metrics.",
            "has_args": false,
            "has_kwargs": false,
            "is_async": false,
            "calls_made": [
              "accuracy_score",
              "f1_score",
              "f1_score",
              "precision_score",
              "recall_score",
              "sum",
              "len",
              "logger.warning",
              "sum",
              "len",
              "sum",
              "len",
              "len",
              "len",
              "len",
              "self.get_label_distribution",
              "self.get_label_distribution",
              "self.metrics_aggregator.add_metrics",
              "enumerate",
              "len",
              "np.mean",
              "np.std",
              "np.min",
              "np.max",
              "len",
              "len",
              "len",
              "len",
              "np.array",
              "np.array",
              "compute_confidence_metrics",
              "metrics.update",
              "compute_risk_aware_metrics",
              "metrics.update",
              "logger.info",
              "compute_ece",
              "compute_mce",
              "compute_brier_score",
              "compute_reliability_diagram_data",
              "np.array",
              "np.array",
              "np.array",
              "np.array",
              "np.array",
              "compute_abstention_metrics",
              "metrics.update",
              "np.array",
              "np.array",
              "len",
              "len",
              "np.zeros",
              "enumerate",
              "logger.warning",
              "result.get",
              "result.get",
              "len",
              "len",
              "set",
              "self._label_to_index",
              "range",
              "np.array",
              "self.conformal_predictor.calibrate",
              "self.conformal_predictor.evaluate_coverage",
              "metrics.update",
              "result.get",
              "result.get",
              "zip",
              "self._label_to_index",
              "self._label_to_index",
              "confidence_metrics.items",
              "self._label_to_index",
              "self._label_to_index",
              "self._label_to_index",
              "self._label_to_index",
              "risk_metrics.items",
              "max",
              "logger.warning",
              "result.get",
              "range",
              "abstention_metrics.items",
              "self._label_to_index",
              "len",
              "coverage_metrics.items"
            ],
            "complexity": 11,
            "return_count": 2,
            "returns_none": false
          },
          "_label_to_index": {
            "name": "_label_to_index",
            "line_start": 470,
            "line_end": 480,
            "line_count": 11,
            "parameters": [
              "self",
              "label"
            ],
            "decorators": [],
            "docstring": "Convert label string to index for advanced metrics.",
            "has_args": false,
            "has_kwargs": false,
            "is_async": false,
            "calls_made": [
              "label_map.get"
            ],
            "complexity": 0,
            "return_count": 1,
            "returns_none": false
          },
          "get_label_distribution": {
            "name": "get_label_distribution",
            "line_start": 482,
            "line_end": 488,
            "line_count": 7,
            "parameters": [
              "self",
              "labels"
            ],
            "decorators": [],
            "docstring": "Get label distribution.",
            "has_args": false,
            "has_kwargs": false,
            "is_async": false,
            "calls_made": [
              "Counter",
              "len",
              "counts.items"
            ],
            "complexity": 0,
            "return_count": 1,
            "returns_none": false
          },
          "create_visualizations": {
            "name": "create_visualizations",
            "line_start": 490,
            "line_end": 558,
            "line_count": 69,
            "parameters": [
              "self",
              "detailed_results",
              "metrics",
              "output_dir"
            ],
            "decorators": [],
            "docstring": "Create evaluation visualizations.",
            "has_args": false,
            "has_kwargs": false,
            "is_async": false,
            "calls_made": [
              "pd.DataFrame",
              "plt.subplots",
              "bar",
              "set_title",
              "set_ylim",
              "bar",
              "set_title",
              "set_ylim",
              "bar",
              "set_title",
              "tick_params",
              "plt.tight_layout",
              "plt.savefig",
              "plt.close",
              "self.create_text_report",
              "logger.info",
              "len",
              "sum",
              "hist",
              "set_title",
              "set_xlabel",
              "set_ylabel",
              "label_dist.keys",
              "label_dist.values",
              "self.create_advanced_visualizations",
              "len",
              "confusion_matrix",
              "sorted",
              "plt.figure",
              "sns.heatmap",
              "plt.title",
              "plt.ylabel",
              "plt.xlabel",
              "plt.tight_layout",
              "plt.savefig",
              "plt.close",
              "list",
              "set",
              "set",
              "unique",
              "unique"
            ],
            "complexity": 4,
            "return_count": 0,
            "returns_none": false
          },
          "create_advanced_visualizations": {
            "name": "create_advanced_visualizations",
            "line_start": 560,
            "line_end": 662,
            "line_count": 103,
            "parameters": [
              "self",
              "metrics",
              "output_dir"
            ],
            "decorators": [],
            "docstring": "Create advanced metrics visualizations.",
            "has_args": false,
            "has_kwargs": false,
            "is_async": false,
            "calls_made": [
              "logger.info",
              "k.replace",
              "plt.figure",
              "plt.subplot",
              "plt.subplot",
              "plt.tight_layout",
              "plt.savefig",
              "plt.close",
              "logger.warning",
              "plt.figure",
              "plt.subplot",
              "plt.plot",
              "plt.scatter",
              "plt.xlabel",
              "plt.ylabel",
              "plt.title",
              "plt.legend",
              "plt.grid",
              "plt.subplot",
              "plt.subplot",
              "plt.subplot",
              "metrics.items",
              "plt.tight_layout",
              "plt.savefig",
              "plt.close",
              "metrics.items",
              "k.startswith",
              "plt.bar",
              "plt.title",
              "plt.ylabel",
              "plt.ylim",
              "list",
              "plt.bar",
              "plt.title",
              "plt.xlabel",
              "plt.ylabel",
              "calibration_metrics.append",
              "calibration_values.append",
              "calibration_metrics.append",
              "calibration_values.append",
              "calibration_metrics.append",
              "calibration_values.append",
              "plt.bar",
              "plt.title",
              "plt.ylabel",
              "plt.bar",
              "plt.title",
              "plt.ylabel",
              "plt.bar",
              "plt.title",
              "plt.xticks",
              "plt.ylabel",
              "conformal_metrics.items",
              "k.startswith",
              "int",
              "size_metrics.values",
              "key.startswith",
              "isinstance",
              "risk_metrics.keys",
              "risk_metrics.values",
              "size_metrics.keys",
              "key.replace",
              "k.split"
            ],
            "complexity": 14,
            "return_count": 0,
            "returns_none": false
          },
          "create_text_report": {
            "name": "create_text_report",
            "line_start": 664,
            "line_end": 745,
            "line_count": 82,
            "parameters": [
              "self",
              "metrics",
              "output_dir"
            ],
            "decorators": [],
            "docstring": "Create a text summary report.",
            "has_args": false,
            "has_kwargs": false,
            "is_async": false,
            "calls_made": [
              "items",
              "items",
              "metrics.items",
              "metrics.items",
              "metrics.items",
              "metrics.items",
              "open",
              "f.write",
              "key.startswith",
              "isinstance",
              "title",
              "key.startswith",
              "isinstance",
              "title",
              "key.startswith",
              "isinstance",
              "title",
              "key.startswith",
              "isinstance",
              "title",
              "replace",
              "replace",
              "replace",
              "replace",
              "key.replace",
              "key.replace",
              "key.replace",
              "key.replace"
            ],
            "complexity": 14,
            "return_count": 0,
            "returns_none": false
          }
        },
        "properties": [],
        "class_variables": [],
        "instance_variables": "{'metrics_aggregator', 'results', 'config', 'metrics', 'config_path', 'risk_controlled_predictor', 'conformal_predictor', 'model_path', 'tokenizer', 'model', 'predictions'}",
        "docstring": "Comprehensive evaluation for fine-tuned LLM models.",
        "complexity_metrics": {
          "method_count": 12,
          "line_count": 703,
          "cyclomatic_complexity": 58,
          "public_methods": 10,
          "private_methods": 2,
          "property_count": 0,
          "inheritance_depth": 0
        }
      }
    },
    "functions": {
      "main": {
        "name": "main",
        "line_start": 748,
        "line_end": 783,
        "line_count": 36,
        "parameters": [],
        "decorators": [],
        "docstring": "Main evaluation function.",
        "has_args": false,
        "has_kwargs": false,
        "is_async": false,
        "calls_made": [
          "argparse.ArgumentParser",
          "parser.add_argument",
          "parser.add_argument",
          "parser.add_argument",
          "parser.add_argument",
          "parser.parse_args",
          "args.test_data.endswith",
          "LLMEvaluator",
          "evaluator.evaluate_dataset",
          "print",
          "print",
          "print",
          "print",
          "print",
          "print",
          "print",
          "print",
          "print",
          "Dataset.from_list",
          "Dataset.load_from_disk",
          "open",
          "json.load"
        ],
        "complexity": 1,
        "return_count": 0,
        "returns_none": false
      },
      "load_test_data": {
        "name": "load_test_data",
        "line_start": 788,
        "line_end": 812,
        "line_count": 25,
        "parameters": [
          "file_path"
        ],
        "decorators": [],
        "docstring": "Load test data from file.\n\nArgs:\n    file_path: Path to test data file\n    \nReturns:\n    List of test data samples",
        "has_args": false,
        "has_kwargs": false,
        "is_async": false,
        "calls_made": [
          "Path",
          "file_path.exists",
          "FileNotFoundError",
          "open",
          "json.load",
          "pd.read_csv",
          "df.to_dict",
          "ValueError"
        ],
        "complexity": 3,
        "return_count": 1,
        "returns_none": false
      },
      "compute_metrics": {
        "name": "compute_metrics",
        "line_start": 815,
        "line_end": 886,
        "line_count": 72,
        "parameters": [
          "predictions",
          "labels",
          "confidences",
          "metrics"
        ],
        "decorators": [],
        "docstring": "Compute evaluation metrics for predictions.\n\nArgs:\n    predictions: List of predicted labels\n    labels: List of true labels\n    confidences: Optional list of confidence scores\n    metrics: Optional list of specific metrics to compute\n    \nReturns:\n    Dictionary of computed metrics",
        "has_args": false,
        "has_kwargs": false,
        "is_async": false,
        "calls_made": [
          "sum",
          "len",
          "len",
          "ValueError",
          "len",
          "len",
          "accuracy_score",
          "list",
          "len",
          "zip",
          "zip",
          "set",
          "len",
          "precision_score",
          "recall_score",
          "f1_score",
          "precision_score",
          "recall_score",
          "f1_score",
          "np.mean",
          "np.std",
          "len",
          "len",
          "len",
          "abs",
          "zip",
          "enumerate",
          "np.mean",
          "np.mean"
        ],
        "complexity": 8,
        "return_count": 2,
        "returns_none": false
      },
      "create_visualizations": {
        "name": "create_visualizations",
        "line_start": 889,
        "line_end": 988,
        "line_count": 100,
        "parameters": [
          "predictions",
          "labels",
          "confidences",
          "save_dir",
          "plots"
        ],
        "decorators": [],
        "docstring": "Create visualizations for evaluation results.\n\nArgs:\n    predictions: List of predicted labels\n    labels: List of true labels\n    confidences: Optional list of confidence scores\n    save_dir: Optional directory to save plots\n    plots: Optional list of specific plots to create",
        "has_args": false,
        "has_kwargs": false,
        "is_async": false,
        "calls_made": [
          "len",
          "len",
          "zip",
          "zip",
          "len",
          "sorted",
          "confusion_matrix",
          "plt.figure",
          "sns.heatmap",
          "plt.title",
          "plt.ylabel",
          "plt.xlabel",
          "plt.close",
          "len",
          "list",
          "plt.savefig",
          "logger.warning",
          "plt.figure",
          "plt.hist",
          "plt.title",
          "plt.xlabel",
          "plt.ylabel",
          "plt.close",
          "logger.warning",
          "len",
          "len",
          "np.linspace",
          "zip",
          "logger.warning",
          "set",
          "plt.savefig",
          "zip",
          "enumerate",
          "any",
          "plt.figure",
          "plt.plot",
          "plt.plot",
          "plt.xlabel",
          "plt.ylabel",
          "plt.title",
          "plt.legend",
          "plt.grid",
          "plt.close",
          "Path",
          "np.mean",
          "np.mean",
          "bin_confidences.append",
          "bin_accuracies.append",
          "plt.savefig",
          "Path",
          "Path",
          "enumerate",
          "enumerate"
        ],
        "complexity": 15,
        "return_count": 1,
        "returns_none": true
      },
      "generate_report": {
        "name": "generate_report",
        "line_start": 991,
        "line_end": 1059,
        "line_count": 69,
        "parameters": [
          "predictions",
          "labels",
          "confidences",
          "metadata",
          "errors",
          "save_path",
          "include_sections"
        ],
        "decorators": [],
        "docstring": "Generate comprehensive evaluation report.\n\nArgs:\n    predictions: List of predicted labels\n    labels: List of true labels\n    confidences: Optional list of confidence scores\n    metadata: Optional metadata about the evaluation\n    errors: Optional list of errors encountered\n    save_path: Optional path to save the report\n    include_sections: Optional list of sections to include\n    \nReturns:\n    Report dictionary",
        "has_args": false,
        "has_kwargs": false,
        "is_async": false,
        "calls_made": [
          "compute_metrics",
          "isoformat",
          "sum",
          "logger.info",
          "len",
          "metrics.get",
          "metrics.get",
          "list",
          "open",
          "json.dump",
          "datetime.now",
          "np.mean",
          "np.std",
          "np.min",
          "np.max",
          "set",
          "len"
        ],
        "complexity": 5,
        "return_count": 1,
        "returns_none": false
      }
    },
    "dependencies": {
      "internal_calls": {
        "global": [
          "logging.getLogger",
          "main"
        ],
        "main": [
          "argparse.ArgumentParser",
          "parser.add_argument",
          "parser.add_argument",
          "parser.add_argument",
          "parser.add_argument",
          "parser.parse_args",
          "args.test_data.endswith",
          "LLMEvaluator",
          "evaluator.evaluate_dataset",
          "print",
          "print",
          "print",
          "print",
          "print",
          "print",
          "print",
          "print",
          "print",
          "Dataset.from_list",
          "Dataset.load_from_disk",
          "open",
          "json.load"
        ],
        "load_test_data": [
          "Path",
          "file_path.exists",
          "FileNotFoundError",
          "open",
          "json.load",
          "pd.read_csv",
          "df.to_dict",
          "ValueError"
        ],
        "compute_metrics": [
          "sum",
          "len",
          "len",
          "ValueError",
          "len",
          "len",
          "accuracy_score",
          "list",
          "len",
          "zip",
          "zip",
          "set",
          "len",
          "precision_score",
          "recall_score",
          "f1_score",
          "precision_score",
          "recall_score",
          "f1_score",
          "np.mean",
          "np.std",
          "len",
          "len",
          "len",
          "abs",
          "zip",
          "enumerate",
          "np.mean",
          "np.mean"
        ],
        "generate_report": [
          "compute_metrics",
          "isoformat",
          "sum",
          "logger.info",
          "len",
          "metrics.get",
          "metrics.get",
          "list",
          "open",
          "json.dump",
          "datetime.now",
          "np.mean",
          "np.std",
          "np.min",
          "np.max",
          "set",
          "len"
        ],
        "LLMEvaluator.load_model": [
          "logger.info",
          "AutoTokenizer.from_pretrained",
          "AutoModelForCausalLM.from_pretrained",
          "logger.info"
        ],
        "LLMEvaluator.evaluate_single": [
          "self.predict_single"
        ],
        "LLMEvaluator.predict_single": [
          "strip",
          "self.tokenizer",
          "self.tokenizer.decode",
          "len",
          "strip",
          "torch.no_grad",
          "self.model.generate",
          "self.tokenizer.decode",
          "generated_text.find",
          "generated_text.rfind",
          "json.loads",
          "result.get",
          "result.get",
          "result.get",
          "result.get"
        ],
        "LLMEvaluator.evaluate_dataset": [
          "logger.info",
          "enumerate",
          "hasattr",
          "hasattr",
          "tqdm",
          "Path",
          "output_dir.mkdir",
          "logger.info",
          "self.predict_single",
          "example.get",
          "pred.get",
          "detailed_results.append",
          "open",
          "json.dump",
          "range",
          "len",
          "example.get",
          "example.get",
          "example.get",
          "example.get",
          "detailed_results.append",
          "logger.warning",
          "len",
          "example.get",
          "example.get",
          "json.loads",
          "example.get",
          "example.get",
          "str",
          "example.get",
          "example.get"
        ],
        "LLMEvaluator.compute_metrics": [
          "accuracy_score",
          "f1_score",
          "f1_score",
          "precision_score",
          "recall_score",
          "sum",
          "len",
          "logger.warning",
          "sum",
          "len",
          "sum",
          "len",
          "len",
          "len",
          "len",
          "self.get_label_distribution",
          "self.get_label_distribution",
          "self.metrics_aggregator.add_metrics",
          "enumerate",
          "len",
          "np.mean",
          "np.std",
          "np.min",
          "np.max",
          "len",
          "len",
          "len",
          "len",
          "np.array",
          "np.array",
          "compute_confidence_metrics",
          "metrics.update",
          "compute_risk_aware_metrics",
          "metrics.update",
          "logger.info",
          "compute_ece",
          "compute_mce",
          "compute_brier_score",
          "compute_reliability_diagram_data",
          "np.array",
          "np.array",
          "np.array",
          "np.array",
          "np.array",
          "compute_abstention_metrics",
          "metrics.update",
          "np.array",
          "np.array",
          "len",
          "len",
          "np.zeros",
          "enumerate",
          "logger.warning",
          "result.get",
          "result.get",
          "len",
          "len",
          "set",
          "self._label_to_index",
          "range",
          "np.array",
          "self.conformal_predictor.calibrate",
          "self.conformal_predictor.evaluate_coverage",
          "metrics.update",
          "result.get",
          "result.get",
          "zip",
          "self._label_to_index",
          "self._label_to_index",
          "confidence_metrics.items",
          "self._label_to_index",
          "self._label_to_index",
          "self._label_to_index",
          "self._label_to_index",
          "risk_metrics.items",
          "max",
          "logger.warning",
          "result.get",
          "range",
          "abstention_metrics.items",
          "self._label_to_index",
          "len",
          "coverage_metrics.items"
        ],
        "LLMEvaluator._label_to_index": [
          "label_map.get"
        ],
        "LLMEvaluator.get_label_distribution": [
          "Counter",
          "len",
          "counts.items"
        ],
        "LLMEvaluator.create_visualizations": [
          "pd.DataFrame",
          "plt.subplots",
          "bar",
          "set_title",
          "set_ylim",
          "bar",
          "set_title",
          "set_ylim",
          "bar",
          "set_title",
          "tick_params",
          "plt.tight_layout",
          "plt.savefig",
          "plt.close",
          "self.create_text_report",
          "logger.info",
          "len",
          "sum",
          "hist",
          "set_title",
          "set_xlabel",
          "set_ylabel",
          "label_dist.keys",
          "label_dist.values",
          "self.create_advanced_visualizations",
          "len",
          "confusion_matrix",
          "sorted",
          "plt.figure",
          "sns.heatmap",
          "plt.title",
          "plt.ylabel",
          "plt.xlabel",
          "plt.tight_layout",
          "plt.savefig",
          "plt.close",
          "list",
          "set",
          "set",
          "unique",
          "unique"
        ],
        "LLMEvaluator.create_text_report": [
          "items",
          "items",
          "metrics.items",
          "metrics.items",
          "metrics.items",
          "metrics.items",
          "open",
          "f.write",
          "key.startswith",
          "isinstance",
          "title",
          "key.startswith",
          "isinstance",
          "title",
          "key.startswith",
          "isinstance",
          "title",
          "key.startswith",
          "isinstance",
          "title",
          "replace",
          "replace",
          "replace",
          "replace",
          "key.replace",
          "key.replace",
          "key.replace",
          "key.replace"
        ],
        "LLMEvaluator.__init__": [
          "Path",
          "self.load_config",
          "MetricsAggregator",
          "self.config.get",
          "get",
          "get",
          "logger.info",
          "evaluate.load",
          "evaluate.load",
          "evaluate.load",
          "evaluate.load",
          "Path",
          "get",
          "get",
          "ConformalPredictor",
          "logger.info",
          "RiskControlledPredictor",
          "logger.info",
          "advanced_config.get",
          "advanced_config.get",
          "Path"
        ],
        "LLMEvaluator.load_config": [
          "open",
          "yaml.safe_load"
        ],
        "LLMEvaluator.create_advanced_visualizations": [
          "logger.info",
          "k.replace",
          "plt.figure",
          "plt.subplot",
          "plt.subplot",
          "plt.tight_layout",
          "plt.savefig",
          "plt.close",
          "logger.warning",
          "plt.figure",
          "plt.subplot",
          "plt.plot",
          "plt.scatter",
          "plt.xlabel",
          "plt.ylabel",
          "plt.title",
          "plt.legend",
          "plt.grid",
          "plt.subplot",
          "plt.subplot",
          "plt.subplot",
          "metrics.items",
          "plt.tight_layout",
          "plt.savefig",
          "plt.close",
          "metrics.items",
          "k.startswith",
          "plt.bar",
          "plt.title",
          "plt.ylabel",
          "plt.ylim",
          "list",
          "plt.bar",
          "plt.title",
          "plt.xlabel",
          "plt.ylabel",
          "calibration_metrics.append",
          "calibration_values.append",
          "calibration_metrics.append",
          "calibration_values.append",
          "calibration_metrics.append",
          "calibration_values.append",
          "plt.bar",
          "plt.title",
          "plt.ylabel",
          "plt.bar",
          "plt.title",
          "plt.ylabel",
          "plt.bar",
          "plt.title",
          "plt.xticks",
          "plt.ylabel",
          "conformal_metrics.items",
          "k.startswith",
          "int",
          "size_metrics.values",
          "key.startswith",
          "isinstance",
          "risk_metrics.keys",
          "risk_metrics.values",
          "size_metrics.keys",
          "key.replace",
          "k.split"
        ],
        "create_visualizations": [
          "len",
          "len",
          "zip",
          "zip",
          "len",
          "sorted",
          "confusion_matrix",
          "plt.figure",
          "sns.heatmap",
          "plt.title",
          "plt.ylabel",
          "plt.xlabel",
          "plt.close",
          "len",
          "list",
          "plt.savefig",
          "logger.warning",
          "plt.figure",
          "plt.hist",
          "plt.title",
          "plt.xlabel",
          "plt.ylabel",
          "plt.close",
          "logger.warning",
          "len",
          "len",
          "np.linspace",
          "zip",
          "logger.warning",
          "set",
          "plt.savefig",
          "zip",
          "enumerate",
          "any",
          "plt.figure",
          "plt.plot",
          "plt.plot",
          "plt.xlabel",
          "plt.ylabel",
          "plt.title",
          "plt.legend",
          "plt.grid",
          "plt.close",
          "Path",
          "np.mean",
          "np.mean",
          "bin_confidences.append",
          "bin_accuracies.append",
          "plt.savefig",
          "Path",
          "Path",
          "enumerate",
          "enumerate"
        ]
      },
      "external_calls": {},
      "attribute_access": {
        "global": [
          "logging.getLogger"
        ],
        "LLMEvaluator.__init__": [
          "self.model",
          "self.tokenizer",
          "self.model_path",
          "self.config_path",
          "self.predictions",
          "self.results",
          "self.metrics_aggregator",
          "self.conformal_predictor",
          "self.risk_controlled_predictor",
          "self.metrics",
          "self.metrics_aggregator",
          "self.load_config",
          "self.config",
          "self.metrics",
          "self.config.get",
          "get",
          "self.conformal_predictor",
          "get",
          "self.risk_controlled_predictor",
          "logger.info",
          "evaluate.load",
          "evaluate.load",
          "evaluate.load",
          "evaluate.load",
          "parent",
          "self.config",
          "get",
          "get",
          "logger.info",
          "logger.info",
          "advanced_config.get",
          "advanced_config.get"
        ],
        "LLMEvaluator.load_model": [
          "self.tokenizer",
          "self.model",
          "logger.info",
          "self.config",
          "AutoTokenizer.from_pretrained",
          "self.model_path",
          "AutoModelForCausalLM.from_pretrained",
          "self.model_path",
          "logger.info",
          "self.config",
          "torch.bfloat16",
          "self.model_path"
        ],
        "main": [
          "argparse.ArgumentParser",
          "parser.add_argument",
          "parser.add_argument",
          "parser.add_argument",
          "parser.add_argument",
          "parser.parse_args",
          "args.test_data.endswith",
          "args.model_path",
          "args.config",
          "evaluator.evaluate_dataset",
          "args.output",
          "args.test_data",
          "Dataset.from_list",
          "Dataset.load_from_disk",
          "args.test_data",
          "args.test_data",
          "json.load"
        ],
        "load_test_data": [
          "file_path.suffix",
          "file_path.exists",
          "file_path.suffix",
          "json.load",
          "pd.read_csv",
          "df.to_dict",
          "file_path.suffix"
        ],
        "LLMEvaluator.load_config": [
          "self.config",
          "self.config_path",
          "yaml.safe_load"
        ],
        "LLMEvaluator.evaluate_single": [
          "self.predict_single"
        ],
        "LLMEvaluator.predict_single": [
          "strip",
          "self.tokenizer",
          "self.tokenizer.decode",
          "strip",
          "json.JSONDecodeError",
          "torch.no_grad",
          "self.model.generate",
          "self.tokenizer",
          "self.tokenizer.decode",
          "generated_text.find",
          "self.model",
          "self.tokenizer.eos_token_id",
          "self.tokenizer",
          "generated_text.rfind",
          "json.loads",
          "self.config",
          "self.tokenizer",
          "result.get",
          "result.get",
          "result.get",
          "result.get"
        ],
        "LLMEvaluator.evaluate_dataset": [
          "logger.info",
          "output_dir.mkdir",
          "logger.info",
          "self.predict_single",
          "example.get",
          "pred.get",
          "detailed_results.append",
          "json.dump",
          "example.get",
          "example.get",
          "example.get",
          "example.get",
          "detailed_results.append",
          "logger.warning",
          "example.get",
          "example.get",
          "json.loads",
          "example.get",
          "example.get",
          "example.get",
          "example.get"
        ],
        "LLMEvaluator.compute_metrics": [
          "self.metrics_aggregator",
          "logger.warning",
          "self.get_label_distribution",
          "self.get_label_distribution",
          "self.metrics_aggregator.add_metrics",
          "np.mean",
          "np.std",
          "np.min",
          "np.max",
          "np.array",
          "np.array",
          "metrics.update",
          "metrics.update",
          "self.conformal_predictor",
          "logger.info",
          "self.metrics_aggregator",
          "np.array",
          "np.array",
          "np.array",
          "np.array",
          "np.array",
          "metrics.update",
          "np.array",
          "np.array",
          "np.zeros",
          "logger.warning",
          "result.get",
          "result.get",
          "self._label_to_index",
          "np.array",
          "self.conformal_predictor.calibrate",
          "self.conformal_predictor.evaluate_coverage",
          "metrics.update",
          "result.get",
          "result.get",
          "self._label_to_index",
          "self._label_to_index",
          "confidence_metrics.items",
          "self._label_to_index",
          "self._label_to_index",
          "self._label_to_index",
          "self._label_to_index",
          "risk_metrics.items",
          "probs.shape",
          "self.conformal_predictor",
          "self.conformal_predictor",
          "logger.warning",
          "result.get",
          "abstention_metrics.items",
          "probs.shape",
          "self._label_to_index",
          "coverage_metrics.items"
        ],
        "LLMEvaluator._label_to_index": [
          "label_map.get"
        ],
        "LLMEvaluator.create_visualizations": [
          "pd.DataFrame",
          "plt.subplots",
          "bar",
          "set_title",
          "set_ylim",
          "bar",
          "set_title",
          "set_ylim",
          "bar",
          "set_title",
          "tick_params",
          "plt.tight_layout",
          "plt.savefig",
          "plt.close",
          "self.create_text_report",
          "logger.info",
          "sum",
          "hist",
          "set_title",
          "set_xlabel",
          "set_ylabel",
          "label_dist.keys",
          "label_dist.values",
          "self.create_advanced_visualizations",
          "plt.figure",
          "sns.heatmap",
          "plt.title",
          "plt.ylabel",
          "plt.xlabel",
          "plt.tight_layout",
          "plt.savefig",
          "plt.close",
          "unique",
          "unique"
        ],
        "LLMEvaluator.create_text_report": [
          "items",
          "items",
          "metrics.items",
          "metrics.items",
          "metrics.items",
          "metrics.items",
          "f.write",
          "key.startswith",
          "title",
          "key.startswith",
          "title",
          "key.startswith",
          "title",
          "key.startswith",
          "title",
          "replace",
          "replace",
          "replace",
          "replace",
          "key.replace",
          "key.replace",
          "key.replace",
          "key.replace"
        ],
        "generate_report": [
          "isoformat",
          "logger.info",
          "metrics.get",
          "metrics.get",
          "json.dump",
          "datetime.now",
          "np.mean",
          "np.std",
          "np.min",
          "np.max"
        ],
        "LLMEvaluator.create_advanced_visualizations": [
          "logger.info",
          "k.replace",
          "plt.figure",
          "plt.subplot",
          "plt.subplot",
          "plt.tight_layout",
          "plt.savefig",
          "plt.close",
          "logger.warning",
          "plt.figure",
          "plt.subplot",
          "plt.plot",
          "plt.scatter",
          "plt.xlabel",
          "plt.ylabel",
          "plt.title",
          "plt.legend",
          "plt.grid",
          "plt.subplot",
          "plt.subplot",
          "plt.subplot",
          "metrics.items",
          "plt.tight_layout",
          "plt.savefig",
          "plt.close",
          "metrics.items",
          "k.startswith",
          "plt.bar",
          "plt.title",
          "plt.ylabel",
          "plt.ylim",
          "plt.bar",
          "plt.title",
          "plt.xlabel",
          "plt.ylabel",
          "calibration_metrics.append",
          "calibration_values.append",
          "calibration_metrics.append",
          "calibration_values.append",
          "calibration_metrics.append",
          "calibration_values.append",
          "plt.bar",
          "plt.title",
          "plt.ylabel",
          "plt.bar",
          "plt.title",
          "plt.ylabel",
          "plt.bar",
          "plt.title",
          "plt.xticks",
          "plt.ylabel",
          "conformal_metrics.items",
          "k.startswith",
          "size_metrics.values",
          "key.startswith",
          "risk_metrics.keys",
          "risk_metrics.values",
          "size_metrics.keys",
          "key.replace",
          "k.split"
        ],
        "compute_metrics": [
          "np.mean",
          "np.std",
          "np.mean",
          "np.mean"
        ],
        "create_visualizations": [
          "plt.figure",
          "sns.heatmap",
          "plt.title",
          "plt.ylabel",
          "plt.xlabel",
          "plt.close",
          "plt.savefig",
          "logger.warning",
          "plt.figure",
          "plt.hist",
          "plt.title",
          "plt.xlabel",
          "plt.ylabel",
          "plt.close",
          "logger.warning",
          "np.linspace",
          "logger.warning",
          "plt.savefig",
          "plt.figure",
          "plt.plot",
          "plt.plot",
          "plt.xlabel",
          "plt.ylabel",
          "plt.title",
          "plt.legend",
          "plt.grid",
          "plt.close",
          "np.mean",
          "np.mean",
          "bin_confidences.append",
          "bin_accuracies.append",
          "plt.savefig"
        ],
        "LLMEvaluator.get_label_distribution": [
          "counts.items"
        ]
      },
      "inheritance_chain": {},
      "composition_relationships": {}
    },
    "call_graph": {
      "LLMEvaluator.__init__": {
        "type": "method",
        "calls": [
          "Path",
          "self.load_config",
          "MetricsAggregator",
          "self.config.get",
          "get",
          "get",
          "logger.info",
          "evaluate.load",
          "evaluate.load",
          "evaluate.load",
          "evaluate.load",
          "Path",
          "get",
          "get",
          "ConformalPredictor",
          "logger.info",
          "RiskControlledPredictor",
          "logger.info",
          "advanced_config.get",
          "advanced_config.get",
          "Path"
        ],
        "called_by": [],
        "complexity": 6,
        "line_count": 67
      },
      "LLMEvaluator.load_config": {
        "type": "method",
        "calls": [
          "open",
          "yaml.safe_load"
        ],
        "called_by": [],
        "complexity": 0,
        "line_count": 4
      },
      "LLMEvaluator.load_model": {
        "type": "method",
        "calls": [
          "logger.info",
          "AutoTokenizer.from_pretrained",
          "AutoModelForCausalLM.from_pretrained",
          "logger.info"
        ],
        "called_by": [],
        "complexity": 0,
        "line_count": 17
      },
      "LLMEvaluator.evaluate_single": {
        "type": "method",
        "calls": [
          "self.predict_single"
        ],
        "called_by": [],
        "complexity": 0,
        "line_count": 3
      },
      "LLMEvaluator.predict_single": {
        "type": "method",
        "calls": [
          "strip",
          "self.tokenizer",
          "self.tokenizer.decode",
          "len",
          "strip",
          "torch.no_grad",
          "self.model.generate",
          "self.tokenizer.decode",
          "generated_text.find",
          "generated_text.rfind",
          "json.loads",
          "result.get",
          "result.get",
          "result.get",
          "result.get"
        ],
        "called_by": [],
        "complexity": 2,
        "line_count": 74
      },
      "LLMEvaluator.evaluate_dataset": {
        "type": "method",
        "calls": [
          "logger.info",
          "enumerate",
          "hasattr",
          "hasattr",
          "tqdm",
          "Path",
          "output_dir.mkdir",
          "logger.info",
          "self.predict_single",
          "example.get",
          "pred.get",
          "detailed_results.append",
          "open",
          "json.dump",
          "range",
          "len",
          "example.get",
          "example.get",
          "example.get",
          "example.get",
          "detailed_results.append",
          "logger.warning",
          "len",
          "example.get",
          "example.get",
          "json.loads",
          "example.get",
          "example.get",
          "str",
          "example.get",
          "example.get"
        ],
        "called_by": [],
        "complexity": 7,
        "line_count": 88
      },
      "LLMEvaluator.compute_metrics": {
        "type": "method",
        "calls": [
          "accuracy_score",
          "f1_score",
          "f1_score",
          "precision_score",
          "recall_score",
          "sum",
          "len",
          "logger.warning",
          "sum",
          "len",
          "sum",
          "len",
          "len",
          "len",
          "len",
          "self.get_label_distribution",
          "self.get_label_distribution",
          "self.metrics_aggregator.add_metrics",
          "enumerate",
          "len",
          "np.mean",
          "np.std",
          "np.min",
          "np.max",
          "len",
          "len",
          "len",
          "len",
          "np.array",
          "np.array",
          "compute_confidence_metrics",
          "metrics.update",
          "compute_risk_aware_metrics",
          "metrics.update",
          "logger.info",
          "compute_ece",
          "compute_mce",
          "compute_brier_score",
          "compute_reliability_diagram_data",
          "np.array",
          "np.array",
          "np.array",
          "np.array",
          "np.array",
          "compute_abstention_metrics",
          "metrics.update",
          "np.array",
          "np.array",
          "len",
          "len",
          "np.zeros",
          "enumerate",
          "logger.warning",
          "result.get",
          "result.get",
          "len",
          "len",
          "set",
          "self._label_to_index",
          "range",
          "np.array",
          "self.conformal_predictor.calibrate",
          "self.conformal_predictor.evaluate_coverage",
          "metrics.update",
          "result.get",
          "result.get",
          "zip",
          "self._label_to_index",
          "self._label_to_index",
          "confidence_metrics.items",
          "self._label_to_index",
          "self._label_to_index",
          "self._label_to_index",
          "self._label_to_index",
          "risk_metrics.items",
          "max",
          "logger.warning",
          "result.get",
          "range",
          "abstention_metrics.items",
          "self._label_to_index",
          "len",
          "coverage_metrics.items"
        ],
        "called_by": [],
        "complexity": 11,
        "line_count": 164
      },
      "LLMEvaluator._label_to_index": {
        "type": "method",
        "calls": [
          "label_map.get"
        ],
        "called_by": [],
        "complexity": 0,
        "line_count": 11
      },
      "LLMEvaluator.get_label_distribution": {
        "type": "method",
        "calls": [
          "Counter",
          "len",
          "counts.items"
        ],
        "called_by": [],
        "complexity": 0,
        "line_count": 7
      },
      "LLMEvaluator.create_visualizations": {
        "type": "method",
        "calls": [
          "pd.DataFrame",
          "plt.subplots",
          "bar",
          "set_title",
          "set_ylim",
          "bar",
          "set_title",
          "set_ylim",
          "bar",
          "set_title",
          "tick_params",
          "plt.tight_layout",
          "plt.savefig",
          "plt.close",
          "self.create_text_report",
          "logger.info",
          "len",
          "sum",
          "hist",
          "set_title",
          "set_xlabel",
          "set_ylabel",
          "label_dist.keys",
          "label_dist.values",
          "self.create_advanced_visualizations",
          "len",
          "confusion_matrix",
          "sorted",
          "plt.figure",
          "sns.heatmap",
          "plt.title",
          "plt.ylabel",
          "plt.xlabel",
          "plt.tight_layout",
          "plt.savefig",
          "plt.close",
          "list",
          "set",
          "set",
          "unique",
          "unique"
        ],
        "called_by": [],
        "complexity": 4,
        "line_count": 69
      },
      "LLMEvaluator.create_advanced_visualizations": {
        "type": "method",
        "calls": [
          "logger.info",
          "k.replace",
          "plt.figure",
          "plt.subplot",
          "plt.subplot",
          "plt.tight_layout",
          "plt.savefig",
          "plt.close",
          "logger.warning",
          "plt.figure",
          "plt.subplot",
          "plt.plot",
          "plt.scatter",
          "plt.xlabel",
          "plt.ylabel",
          "plt.title",
          "plt.legend",
          "plt.grid",
          "plt.subplot",
          "plt.subplot",
          "plt.subplot",
          "metrics.items",
          "plt.tight_layout",
          "plt.savefig",
          "plt.close",
          "metrics.items",
          "k.startswith",
          "plt.bar",
          "plt.title",
          "plt.ylabel",
          "plt.ylim",
          "list",
          "plt.bar",
          "plt.title",
          "plt.xlabel",
          "plt.ylabel",
          "calibration_metrics.append",
          "calibration_values.append",
          "calibration_metrics.append",
          "calibration_values.append",
          "calibration_metrics.append",
          "calibration_values.append",
          "plt.bar",
          "plt.title",
          "plt.ylabel",
          "plt.bar",
          "plt.title",
          "plt.ylabel",
          "plt.bar",
          "plt.title",
          "plt.xticks",
          "plt.ylabel",
          "conformal_metrics.items",
          "k.startswith",
          "int",
          "size_metrics.values",
          "key.startswith",
          "isinstance",
          "risk_metrics.keys",
          "risk_metrics.values",
          "size_metrics.keys",
          "key.replace",
          "k.split"
        ],
        "called_by": [],
        "complexity": 14,
        "line_count": 103
      },
      "LLMEvaluator.create_text_report": {
        "type": "method",
        "calls": [
          "items",
          "items",
          "metrics.items",
          "metrics.items",
          "metrics.items",
          "metrics.items",
          "open",
          "f.write",
          "key.startswith",
          "isinstance",
          "title",
          "key.startswith",
          "isinstance",
          "title",
          "key.startswith",
          "isinstance",
          "title",
          "key.startswith",
          "isinstance",
          "title",
          "replace",
          "replace",
          "replace",
          "replace",
          "key.replace",
          "key.replace",
          "key.replace",
          "key.replace"
        ],
        "called_by": [],
        "complexity": 14,
        "line_count": 82
      },
      "main": {
        "type": "function",
        "calls": [
          "argparse.ArgumentParser",
          "parser.add_argument",
          "parser.add_argument",
          "parser.add_argument",
          "parser.add_argument",
          "parser.parse_args",
          "args.test_data.endswith",
          "LLMEvaluator",
          "evaluator.evaluate_dataset",
          "print",
          "print",
          "print",
          "print",
          "print",
          "print",
          "print",
          "print",
          "print",
          "Dataset.from_list",
          "Dataset.load_from_disk",
          "open",
          "json.load"
        ],
        "called_by": [],
        "complexity": 1,
        "line_count": 36
      },
      "load_test_data": {
        "type": "function",
        "calls": [
          "Path",
          "file_path.exists",
          "FileNotFoundError",
          "open",
          "json.load",
          "pd.read_csv",
          "df.to_dict",
          "ValueError"
        ],
        "called_by": [],
        "complexity": 3,
        "line_count": 25
      },
      "compute_metrics": {
        "type": "function",
        "calls": [
          "sum",
          "len",
          "len",
          "ValueError",
          "len",
          "len",
          "accuracy_score",
          "list",
          "len",
          "zip",
          "zip",
          "set",
          "len",
          "precision_score",
          "recall_score",
          "f1_score",
          "precision_score",
          "recall_score",
          "f1_score",
          "np.mean",
          "np.std",
          "len",
          "len",
          "len",
          "abs",
          "zip",
          "enumerate",
          "np.mean",
          "np.mean"
        ],
        "called_by": [
          "generate_report"
        ],
        "complexity": 8,
        "line_count": 72
      },
      "create_visualizations": {
        "type": "function",
        "calls": [
          "len",
          "len",
          "zip",
          "zip",
          "len",
          "sorted",
          "confusion_matrix",
          "plt.figure",
          "sns.heatmap",
          "plt.title",
          "plt.ylabel",
          "plt.xlabel",
          "plt.close",
          "len",
          "list",
          "plt.savefig",
          "logger.warning",
          "plt.figure",
          "plt.hist",
          "plt.title",
          "plt.xlabel",
          "plt.ylabel",
          "plt.close",
          "logger.warning",
          "len",
          "len",
          "np.linspace",
          "zip",
          "logger.warning",
          "set",
          "plt.savefig",
          "zip",
          "enumerate",
          "any",
          "plt.figure",
          "plt.plot",
          "plt.plot",
          "plt.xlabel",
          "plt.ylabel",
          "plt.title",
          "plt.legend",
          "plt.grid",
          "plt.close",
          "Path",
          "np.mean",
          "np.mean",
          "bin_confidences.append",
          "bin_accuracies.append",
          "plt.savefig",
          "Path",
          "Path",
          "enumerate",
          "enumerate"
        ],
        "called_by": [],
        "complexity": 15,
        "line_count": 100
      },
      "generate_report": {
        "type": "function",
        "calls": [
          "compute_metrics",
          "isoformat",
          "sum",
          "logger.info",
          "len",
          "metrics.get",
          "metrics.get",
          "list",
          "open",
          "json.dump",
          "datetime.now",
          "np.mean",
          "np.std",
          "np.min",
          "np.max",
          "set",
          "len"
        ],
        "called_by": [],
        "complexity": 5,
        "line_count": 69
      }
    },
    "data_flow": {
      "global_variables": [
        "logger"
      ],
      "shared_state": {},
      "parameter_flow": {
        "LLMEvaluator.__init__": {
          "parameters": [
            "self",
            "model",
            "tokenizer",
            "model_path",
            "config_path"
          ],
          "parameter_count": 5,
          "has_self": true,
          "has_kwargs": false,
          "has_args": false
        },
        "LLMEvaluator.load_config": {
          "parameters": [
            "self"
          ],
          "parameter_count": 1,
          "has_self": true,
          "has_kwargs": false,
          "has_args": false
        },
        "LLMEvaluator.load_model": {
          "parameters": [
            "self"
          ],
          "parameter_count": 1,
          "has_self": true,
          "has_kwargs": false,
          "has_args": false
        },
        "LLMEvaluator.evaluate_single": {
          "parameters": [
            "self",
            "text",
            "parse_json"
          ],
          "parameter_count": 3,
          "has_self": true,
          "has_kwargs": false,
          "has_args": false
        },
        "LLMEvaluator.predict_single": {
          "parameters": [
            "self",
            "text",
            "metadata"
          ],
          "parameter_count": 3,
          "has_self": true,
          "has_kwargs": false,
          "has_args": false
        },
        "LLMEvaluator.evaluate_dataset": {
          "parameters": [
            "self",
            "dataset",
            "batch_size",
            "output_path"
          ],
          "parameter_count": 4,
          "has_self": true,
          "has_kwargs": false,
          "has_args": false
        },
        "LLMEvaluator.compute_metrics": {
          "parameters": [
            "self",
            "predictions",
            "ground_truth",
            "detailed_results"
          ],
          "parameter_count": 4,
          "has_self": true,
          "has_kwargs": false,
          "has_args": false
        },
        "LLMEvaluator._label_to_index": {
          "parameters": [
            "self",
            "label"
          ],
          "parameter_count": 2,
          "has_self": true,
          "has_kwargs": false,
          "has_args": false
        },
        "LLMEvaluator.get_label_distribution": {
          "parameters": [
            "self",
            "labels"
          ],
          "parameter_count": 2,
          "has_self": true,
          "has_kwargs": false,
          "has_args": false
        },
        "LLMEvaluator.create_visualizations": {
          "parameters": [
            "self",
            "detailed_results",
            "metrics",
            "output_dir"
          ],
          "parameter_count": 4,
          "has_self": true,
          "has_kwargs": false,
          "has_args": false
        },
        "LLMEvaluator.create_advanced_visualizations": {
          "parameters": [
            "self",
            "metrics",
            "output_dir"
          ],
          "parameter_count": 3,
          "has_self": true,
          "has_kwargs": false,
          "has_args": false
        },
        "LLMEvaluator.create_text_report": {
          "parameters": [
            "self",
            "metrics",
            "output_dir"
          ],
          "parameter_count": 3,
          "has_self": true,
          "has_kwargs": false,
          "has_args": false
        }
      },
      "return_patterns": {
        "LLMEvaluator.__init__": {
          "return_statements": 0,
          "returns_none": false,
          "return_complexity": "single"
        },
        "LLMEvaluator.load_config": {
          "return_statements": 0,
          "returns_none": false,
          "return_complexity": "single"
        },
        "LLMEvaluator.load_model": {
          "return_statements": 0,
          "returns_none": false,
          "return_complexity": "single"
        },
        "LLMEvaluator.evaluate_single": {
          "return_statements": 1,
          "returns_none": false,
          "return_complexity": "single"
        },
        "LLMEvaluator.predict_single": {
          "return_statements": 3,
          "returns_none": false,
          "return_complexity": "multiple"
        },
        "LLMEvaluator.evaluate_dataset": {
          "return_statements": 2,
          "returns_none": false,
          "return_complexity": "multiple"
        },
        "LLMEvaluator.compute_metrics": {
          "return_statements": 2,
          "returns_none": false,
          "return_complexity": "multiple"
        },
        "LLMEvaluator._label_to_index": {
          "return_statements": 1,
          "returns_none": false,
          "return_complexity": "single"
        },
        "LLMEvaluator.get_label_distribution": {
          "return_statements": 1,
          "returns_none": false,
          "return_complexity": "single"
        },
        "LLMEvaluator.create_visualizations": {
          "return_statements": 0,
          "returns_none": false,
          "return_complexity": "single"
        },
        "LLMEvaluator.create_advanced_visualizations": {
          "return_statements": 0,
          "returns_none": false,
          "return_complexity": "single"
        },
        "LLMEvaluator.create_text_report": {
          "return_statements": 0,
          "returns_none": false,
          "return_complexity": "single"
        }
      }
    },
    "analysis_metadata": {
      "timestamp": "2025-08-14T18:24:47.638438Z",
      "analyzer_version": "1.0.0",
      "file_analyzed": "C:\\Users\\Kevin\\fine_tune_llm\\backups\\god_classes\\evaluate_backup_20250814_121303.py",
      "analysis_complete": true
    }
  },
  "summary_report": {
    "file_summary": {
      "file_path": "C:\\Users\\Kevin\\fine_tune_llm\\backups\\god_classes\\evaluate_backup_20250814_121303.py",
      "total_classes": 1,
      "total_methods": 12,
      "total_functions": 5,
      "total_imports": 10,
      "lines_of_code": 885,
      "total_complexity": 58
    },
    "complexity_analysis": {
      "average_methods_per_class": 12.0,
      "most_complex_class": {
        "name": "LLMEvaluator",
        "complexity": 58,
        "method_count": 12,
        "line_count": 703
      },
      "most_connected_method": {
        "name": "LLMEvaluator.compute_metrics",
        "total_connections": 83,
        "outgoing_calls": 83,
        "incoming_calls": 0
      },
      "dependency_density": 1.0
    },
    "decomposition_candidates": [
      {
        "class_name": "LLMEvaluator",
        "reason": "god_class",
        "method_count": 12,
        "complexity": 58,
        "line_count": 703,
        "decomposition_suggestions": [
          "Extract create-related methods into separate class"
        ]
      }
    ],
    "external_dependencies": {
      "third_party_imports": [
        "numpy",
        "pandas",
        "torch",
        "matplotlib.pyplot",
        "seaborn"
      ],
      "high_coupling_indicators": [
        "Highly connected methods: 11"
      ]
    }
  }
}