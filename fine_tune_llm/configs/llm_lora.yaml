# LoRA SFT configuration for LLM fine-tuning
# Multi-model support
model_options:
  glm-4.5-air:
    model_id: ZHIPU-AI/glm-4-9b-chat
    tokenizer_id: ZHIPU-AI/glm-4-9b-chat
    target_modules: ["query_key_value", "dense", "dense_h_to_4h", "dense_4h_to_h"]
    chat_template: "glm"
  qwen2.5-7b:
    model_id: Qwen/Qwen2.5-7B
    tokenizer_id: Qwen/Qwen2.5-7B
    target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
    chat_template: "qwen"
  mistral-7b:
    model_id: mistralai/Mistral-7B-v0.1
    tokenizer_id: mistralai/Mistral-7B-v0.1
    target_modules: ["q_proj", "k_proj", "v_proj", "o_proj"]
    chat_template: "mistral"
  llama-3-8b:
    model_id: meta-llama/Meta-Llama-3-8B
    tokenizer_id: meta-llama/Meta-Llama-3-8B
    target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
    chat_template: "llama"

selected_model: glm-4.5-air  # Default

lora:
  # LoRA/DoRA/AdaLoRA parameters
  method: lora  # Options: lora, dora, adalora
  r: 16  # Rank (initial rank for AdaLoRA)
  lora_alpha: 32
  lora_dropout: 0.1
  
  # AdaLoRA specific parameters
  adalora:
    target_r: 8  # Target rank after pruning
    init_r: 12   # Initial rank (if different from r)
    tinit: 0     # Warmup steps before pruning
    tfinal: 0    # Steps after which stop pruning (0 = auto)
    deltaT: 1    # Update frequency for importance score
  
  # QLoRA quantization settings
  quantization:
    enabled: false  # Default off for backward compatibility
    bits: 4  # Options: 4 or 8
    compute_dtype: bfloat16  # For mixed precision
    double_quant: true  # Extra memory savings
    quant_type: nf4  # Normalized float4

# Advanced PEFT configurations
peft:
  # DyLoRA - Dynamic Search-Free Low-Rank Adaptation
  dylora:
    enabled: false  # Set to true to enable DyLoRA
    init_r: 16  # Initial rank (adjust dynamically during training)
    target_r: 32  # Target rank for adaptation
    precision_penalty_weight: 0.5  # Weight for false-positive regularization in loss
    dynamic_adjustment_interval: 100  # Steps between rank adjustments
    precision_threshold: 0.95  # Minimum precision for high-stakes tasks
  
  # LoRA-FA - Memory-Efficient Low-Rank Adaptation
  lorafa:
    enabled: false
    projection_dim: 16  # Dimension for frozen random projection
    calibration_weight: 0.2  # Weight for calibration loss to ensure precise confidence
    freeze_A_matrix: true  # Freeze A matrix as random projection
  
  # SparseLoRA - Contextual sparsity for acceleration
  sparse_lora:
    enabled: false
    sparsity_ratio: 0.5  # Ratio of sparse activations
    confidence_threshold: 0.8  # Activate only high-confidence paths
    
# Training configuration
training:
  # Basic parameters
  learning_rate: 2e-4
  num_epochs: 3
  batch_size: 4
  gradient_accumulation_steps: 4
  warmup_ratio: 0.03
  weight_decay: 0.001
  max_grad_norm: 0.3
  
  # Learning rate scheduler
  scheduler:
    type: cosine  # Options: cosine, linear, none
    warmup_steps: 100  # 10% of total steps recommended
  
  # Sequence parameters
  max_length: 2048
  padding: true
  truncation: true
  
  # Training optimizations
  fp16: false
  bf16: true  # Use bfloat16 for better stability
  gradient_checkpointing: true
  optim: paged_adamw_32bit
  
  # Data configuration
  packing: true  # Pack multiple examples per sequence
  num_proc: 4  # Parallel data processing
  
  # Evaluation
  eval_steps: 100
  save_steps: 200
  logging_steps: 10
  eval_strategy: steps
  save_total_limit: 3
  load_best_model_at_end: true
  metric_for_best_model: eval_f1
  greater_is_better: true
  
  # Early stopping
  early_stopping: true
  early_stopping_patience: 3
  
  # Logging and monitoring
  logging:
    wandb: false  # Enable Weights & Biases logging
    project_name: "llm-finetuning"
    entity: null  # W&B team/entity name (optional)
    run_name: null  # Auto-generated if null
    tags: ["lora", "finetuning"]
    notes: "LLM fine-tuning experiment"
  
  # Half Fine-Tuning (HFT)
  hft:
    enabled: false
    update_fraction: 0.5  # Fraction of parameters to update per round
    precision_select_layers: true  # Select layers with highest precision impact
    layer_selection_interval: 100  # Steps between layer selection updates
  
  # Forward Pass-Only Fine-Tuning
  forward_only:
    enabled: false
    num_forward_passes: 5  # For ensemble-like precision
    consistency_threshold: 0.9  # Require agreement for high-stakes output
    use_in_context_learning: true  # Use ICL instead of backprop

# Evaluation configuration
evaluation:
  enabled: true
  metrics: ["accuracy", "f1"]
  val_split: 0.1  # Fraction of data for validation

# Data augmentation
data:
  augmentation:
    enabled: false
    methods: ["synonym_replacement", "random_insertion"]
    aug_p: 0.1  # Probability of augmentation

# Output configuration
output:
  structured: false  # Enable for enforced JSON
  schema: '{"decision": "str", "rationale": "str", "abstain": "bool"}'  # JSON schema
  
# Instruction format
instruction_format:
  system_prompt: |
    You are a specialized classifier for bird flu content. 
    Analyze the text and return a JSON response with your classification.
    You MUST return valid JSON with "decision", "rationale", and "abstain" fields.
    If you are uncertain or the text is ambiguous, set "abstain": true.
    
  input_template: |
    Text to classify:
    {text}
    
    Metadata:
    {metadata}
    
  output_template: |
    {
      "decision": "{label}",
      "rationale": "{rationale}",
      "abstain": {abstain}
    }
    
  abstain_examples:
    - text: "The document appears corrupted with mixed languages and symbols..."
      output: |
        {
          "decision": null,
          "rationale": "Text appears corrupted or unintelligible",
          "abstain": true
        }
    - text: "This might be about birds or it might be about flu but I'm not sure..."
      output: |
        {
          "decision": null,
          "rationale": "Ambiguous content without clear indicators",
          "abstain": true
        }

# Mixture-Based Architectures
moe:
  enabled: false
  num_experts: 4  # E.g., one for bird flu classification, one for general
  top_k: 2  # Activate top-k experts
  precision_gate: true  # Gate based on historical precision per expert
  expert_capacity_factor: 1.25  # Capacity factor for balanced routing
  
moa:
  enabled: false
  agents:
    - type: fact_check
      model: "glm-4.5-air"
    - type: classify
      model: "llama-3-8b"
  collaboration_mode: "sequential"  # Or parallel for precision voting
  voting_threshold: 0.8  # Agreement threshold for parallel mode

# Optimization and Preference Alignment
alignment:
  orpo:
    enabled: false
    beta: 0.1  # Low for conservative, precise preferences
    preference_data_path: "data/preferences.json"  # Path to pairwise data
    factuality_threshold: 0.95  # Minimum factuality score for high-stakes
  
  dpo:
    enabled: false
    beta: 0.1
    reference_model: null  # Path to reference model
  
  ppo:
    enabled: false
    reward_model: null  # Path to reward model
    kl_penalty: 0.02

# Pruning and Efficiency
pruning:
  enabled: false
  ratio: 0.2  # Prune 20% parameters
  method: "magnitude"  # Or "random"; precision-opt: prune low-precision contributing params
  importance_type: "precision"  # Use precision-based importance scoring
  
eas:  # Efficient Attention Skipping
  enabled: false
  skip_ratio: 0.3  # Skip 30% of attention heads
  confidence_based: true  # Skip low-confidence attention heads

# Memory-Efficient Optimizers
lomo:  # Low-Memory Optimization
  enabled: false
  adaptive_lr: true  # Adaptive learning rates based on precision gradients
  memory_budget: 8  # GB
  
mezo:  # Memory-Efficient Zeroth-Order Optimizer
  enabled: false
  perturbation_scale: 1e-3
  num_forward_passes: 2
  precision_direction: true  # Perturb towards higher precision directions

# Data-Efficient Fine-Tuning
deft:
  enabled: false
  influence_score_method: "precision"  # Prioritize data with high precision influence
  data_fraction: 0.5  # Use top 50% influential data
  
continuous_learning:
  enabled: false
  replay_buffer_size: 1000
  high_precision_examples_only: true  # Only store examples with >0.95 precision
  incremental_update_interval: 500  # Steps

# Domain-Specific and Safety
domain_specific:
  enabled: false
  domain: "medical"  # e.g., medical, legal, financial
  safety_constraints: true
  factuality_checks: true
  
safety_tools:
  llama_guard:
    enabled: false
    model_path: "meta-llama/LlamaGuard-7b"
    threshold: 0.9
  
  shield_gemma:
    enabled: false
    model_path: "google/shieldgemma-2b"
    categories: ["harm", "bias", "toxicity"]

# Over-Memorization Mitigation
memorization:
  enabled: false
  regularization_weight: 0.1
  diversity_penalty: 0.05
  generalization_threshold: 0.8

# Verifiable Fine-Tuning
verifiable:
  enabled: false
  backdoor_key: null  # Cryptographic key for verification
  audit_log_path: "artifacts/audit_log.json"

# Hardware Optimization
hardware:
  custom_accelerator: false
  sparse_kernels: false
  low_precision_mode: false
  
# Data Quality and Preprocessing
data_quality:
  purification:
    enabled: false
    safety_filter: true
    quality_threshold: 0.8
    
  high_stakes_preprocessing:
    enabled: false
    imbalance_handling: "smote"  # SMOTE, undersampling, or class_weight
    quality_checks: true
    precision_focus: true